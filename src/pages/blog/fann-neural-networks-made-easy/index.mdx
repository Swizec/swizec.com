---
title: "FANN - neural networks made easy"
description: ""
published: 2012-02-20
redirect_from:
  - /blog/fann-neural-networks-made-easy/swizec/3714
categories: "Uncategorized"
hero: ../../../defaultHero.jpg
---

[![Convergence!](https://swizec.com/wp-content/uploads/2012/02/Selection_053-300x174.png)](https://swizec.com/wp-content/uploads/2012/02/Selection_053-300x174.png)

Over the weekend I was struck with the realization that I don't know \_how to use [neural networks](http://en.wikipedia.org/wiki/Neural_network) in practice, damn it. \_Even though a few months ago [I realized what neural networks are](https://swizec.com/blog/i-think-i-finally-understand-what-a-neural-network-is/), even though I've [tried implementing them](https://swizec.com/blog/i-suck-at-implementing-neural-networks-in-octave/), even though I've used them in a class setting ...

How the hell do you use these things in real life!?

Implement from scratch? ... no that can't be it.

Find a library, write some code, run some tests, fiddle with features, run a test, fiddle with features, realize everything is slow, decide to use more layers, fiddle with features, play around with activation functions, run a test, fiddle with features, rewrite the code because it's a mess, fiddle with features, run a test, run the network, run more tests and so on and on _ad nauseum_.

That can't be it either ...

## FANN

Looking far and wide for a good library to use I stumbled upon [FANN - Fast Artificial Neural Networks](http://leenissen.dk/fann/wp/).

> Fast Artificial Neural Network Library is a free open source neural network library, which implements multilayer artificial neural networks in C with support for both fully connected and sparsely connected networks. Cross-platform execution in both fixed and floating point are supported. It includes a framework for easy handling of [training data](http://en.wikipedia.org/wiki/Training_set) sets. It is easy to use, versatile, well documented, and fast. Bindings to more than [15 programming languages](http://leenissen.dk/fann/wp/language-bindings/) are available. An easy to read introduction [article](http://fann.sf.net/fann_en.pdf) and a [reference manual](http://leenissen.dk/fann/html/index.html) accompanies the library with examples and recommendations on how to use the library. Several graphical [user interfaces](http://leenissen.dk/fann/wp/graphical-interface/) are also available for the library.

Perfect!

Not only has someone gone to the trouble of implementing everything and making sure it works - nothing sucks more than figuring out whether you're using your learning software wrong or it's just buggy - they even gave it all the fiddly features I need!

It gets better! There's a slew of graphical interfaces -> You get to play with the fiddly bits without even knowing what you're doing! Yes!

Put the data in the fann format, load it up, and away you go. Playing around until you figure out what you're looking for, then you can just implement the same thing with the FANN binding of your choice.

[![It can suggest a good training algo](https://swizec.com/wp-content/uploads/2012/02/Selection_050.png)](https://swizec.com/wp-content/uploads/2012/02/Selection_050.png)
[![You get to set up the neural network](https://swizec.com/wp-content/uploads/2012/02/Selection_052.png)](https://swizec.com/wp-content/uploads/2012/02/Selection_052.png)
[![Fiddly bits!](https://swizec.com/wp-content/uploads/2012/02/Selection_051.png)](https://swizec.com/wp-content/uploads/2012/02/Selection_051.png)
[![Watch it converge in real time](https://swizec.com/wp-content/uploads/2012/02/Selection_053.png)](https://swizec.com/wp-content/uploads/2012/02/Selection_053.png)

## Done in a few hours

FANN really saved my skin last night. At least the [GUI](http://en.wikipedia.org/wiki/Graphical_user_interface) did. I still haven't solved my problem - trying to predict how many people will read a whole post - but it took me literally a couple of minutes to realize that the same network can't be used to predict two outputs since it won't even converge.

That's something very specific to the problem.

I also realized the networks were overfitting my data, then performing poorly on the test.

Another specific thing.

It is because of this incredibly problem-specific nature of most work involving neural networks that having tools like these is really important. Who wants to fiddle around with implementing all this stuff by hand for several hours before even running the first tests?

I probably ran twenty or thirty different configurations in the space of three hours last night. Could I have done that without a simple tool? Probably not - wouldn't even have the first configuration implemented by now.

Now if only the GUI tool calculated precision and recall instead of mean standard error ...